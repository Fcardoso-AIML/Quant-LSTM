{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import yfinance as yf\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd1a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "lookback = 60\n",
    "horizon = 30\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "hidden_size = 128\n",
    "num_stacked_layers = 3\n",
    "dropout = 0.1\n",
    "quantiles = [0.1, 0.5, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53945ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = yf.Ticker(\"BTC-USD\").history(period=\"1y\", interval=\"1d\")\n",
    "df.reset_index(inplace=True)\n",
    "df = df.iloc[::-1]\n",
    "df[\"Price\"] = df[\"Close\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2b7f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_lstm_data(df, target_column=\"Price\", lookback=60, horizon=30, scaler_type=\"robust\"):\n",
    "    df = df.copy()\n",
    "    df.set_index(\"Date\", inplace=True)\n",
    "    df = df[[target_column]].copy()\n",
    "    df[target_column] = df[target_column].shift(-horizon)\n",
    "\n",
    "    for i in range(1, lookback + 1):\n",
    "        df[f'{target_column}(t-{i})'] = df[target_column].shift(i)\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    data_np = df.to_numpy()\n",
    "\n",
    "    scaler = RobustScaler() if scaler_type == \"robust\" else MinMaxScaler(feature_range=(-1, 1))\n",
    "    split_index = int(len(data_np) * 0.8)\n",
    "    scaler.fit(data_np[:split_index])\n",
    "    data_np = scaler.transform(data_np)\n",
    "\n",
    "    X = np.flip(data_np[:, 1:], axis=1).copy()\n",
    "    y = data_np[:, 0]\n",
    "\n",
    "    X_train, y_train = X[:split_index], y[:split_index]\n",
    "    X_test, y_test = X[split_index:], y[split_index:]\n",
    "\n",
    "    X_train = X_train.reshape((-1, lookback, 1))\n",
    "    X_test = X_test.reshape((-1, lookback, 1))\n",
    "    y_train = y_train.reshape((-1, 1))\n",
    "    y_test = y_test.reshape((-1, 1))\n",
    "\n",
    "    return (torch.tensor(X_train).float(), torch.tensor(y_train).float(),\n",
    "            torch.tensor(X_test).float(), torch.tensor(y_test).float(),\n",
    "            scaler)\n",
    "\n",
    "class TSData(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X, self.y = X, y\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
    "    \n",
    "def quantile_loss(preds, target, quantiles):\n",
    "    losses = []\n",
    "    for i, q in enumerate(quantiles):\n",
    "        errors = target - preds[:, i].unsqueeze(1)\n",
    "        loss = torch.max((q - 1) * errors, q * errors)\n",
    "        losses.append(torch.mean(loss))\n",
    "    return torch.stack(losses).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d61a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class QuantileLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, num_quantiles):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_quantiles)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if \"weight\" in name and param.dim() > 1:\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif \"bias\" in name:\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        h0 = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.lstm.num_layers, batch_size, self.lstm.hidden_size).to(x.device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.layer_norm(out[:, -1, :])\n",
    "        return self.fc(out)\n",
    "\n",
    "def inverse_transform(y_scaled, scaler, lookback):\n",
    "    dummy = np.zeros((len(y_scaled), lookback + 1))\n",
    "    dummy[:, 0] = y_scaled\n",
    "    return scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "def evaluate_quantile_predictions(model, X_train, y_train, X_test, y_test, scaler, lookback):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_preds = model(X_train.to(device)).cpu().numpy()\n",
    "        test_preds = model(X_test.to(device)).cpu().numpy()\n",
    "\n",
    "    train_q50 = inverse_transform(train_preds[:, 1], scaler, lookback)\n",
    "    train_actual = inverse_transform(y_train.cpu().numpy().flatten(), scaler, lookback)\n",
    "    \n",
    "    test_q10 = inverse_transform(test_preds[:, 0], scaler, lookback)\n",
    "    test_q50 = inverse_transform(test_preds[:, 1], scaler, lookback)\n",
    "    test_q90 = inverse_transform(test_preds[:, 2], scaler, lookback)\n",
    "    test_actual = inverse_transform(y_test.cpu().numpy().flatten(), scaler, lookback)\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(train_actual, label=\"Training Actual\", color=\"black\")\n",
    "    plt.plot(train_q50, label=\"Training Predictions\", color=\"blue\")\n",
    "    plt.title(f\"Training Data: Predictions vs Actual\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(test_actual, label=\"Test Actual\", color=\"black\")\n",
    "    plt.plot(test_q50, label=\"Test Predictions\", color=\"blue\")\n",
    "    plt.fill_between(range(len(test_actual)), test_q10, test_q90, color=\"gray\", alpha=0.3, \n",
    "                    label=\"80% Prediction Interval\")\n",
    "    plt.title(f\"Test Data: Predictions vs Actual ({horizon}-day ahead)\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    mae = np.mean(np.abs(test_actual - test_q50))\n",
    "    rmse = np.sqrt(np.mean((test_actual - test_q50)**2))\n",
    "    mape = np.mean(np.abs((test_actual - test_q50) / test_actual)) * 100\n",
    "    \n",
    "    print(f\"\\nTest Set Metrics:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"train_actual\": train_actual,\n",
    "        \"train_pred\": train_q50,\n",
    "        \"test_actual\": test_actual,\n",
    "        \"test_q10\": test_q10,\n",
    "        \"test_q50\": test_q50,\n",
    "        \"test_q90\": test_q90\n",
    "    }\n",
    "\n",
    "def forecast_next_days(model, X_last_window, scaler, lookback, horizon, quantiles):\n",
    "    model.eval()\n",
    "    preds_q10, preds_q50, preds_q90 = [], [], []\n",
    "\n",
    "    current_input = X_last_window.clone().to(device)\n",
    "\n",
    "    for _ in range(horizon):\n",
    "        with torch.no_grad():\n",
    "            out = model(current_input)\n",
    "            q10, q50, q90 = out[0].cpu().numpy()\n",
    "            preds_q10.append(q10)\n",
    "            preds_q50.append(q50)\n",
    "            preds_q90.append(q90)\n",
    "\n",
    "        next_step = q50 + np.random.normal(0, abs(q90 - q10) / 4)\n",
    "        next_step_tensor = torch.tensor([[[next_step]]], dtype=torch.float32).to(device)\n",
    "        current_input = torch.cat([current_input[:, 1:, :], next_step_tensor], dim=1)\n",
    "\n",
    "    def inv(preds_scaled):\n",
    "        dummy = np.zeros((len(preds_scaled), lookback + 1))\n",
    "        dummy[:, 0] = preds_scaled\n",
    "        return scaler.inverse_transform(dummy)[:, 0]\n",
    "\n",
    "    return {\n",
    "        \"q10\": inv(preds_q10),\n",
    "        \"q50\": inv(preds_q50),\n",
    "        \"q90\": inv(preds_q90)\n",
    "    }\n",
    "\n",
    "def plot_forecast(forecast_dict, last_actual=None):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Set seaborn style\n",
    "    sns.set(style=\"whitegrid\", rc={\"grid.linewidth\": 0.5, \"grid.alpha\": 0.5})\n",
    "    sns.set_context(\"notebook\", font_scale=1.2)\n",
    "    \n",
    "    # Get forecast data\n",
    "    q10 = forecast_dict[\"q10\"]\n",
    "    q50 = forecast_dict[\"q50\"]\n",
    "    q90 = forecast_dict[\"q90\"]\n",
    "    \n",
    "    # Create dataframe for easy plotting\n",
    "    df = pd.DataFrame({\n",
    "        'Day': range(len(q50)),\n",
    "        'Lower Bound (q10)': q10,\n",
    "        'Median Forecast (q50)': q50,\n",
    "        'Upper Bound (q90)': q90\n",
    "    })\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    \n",
    "    # Plot the prediction interval\n",
    "    ax = plt.gca()\n",
    "    ax.fill_between(df['Day'], df['Lower Bound (q10)'], df['Upper Bound (q90)'], \n",
    "                    color='lightsteelblue', alpha=0.5, label='80% Prediction Interval')\n",
    "    \n",
    "    # Plot the quantile lines\n",
    "    sns.lineplot(data=df, x='Day', y='Median Forecast (q50)', \n",
    "                 color='royalblue', linewidth=3, label='Median Forecast (q50)')\n",
    "    sns.lineplot(data=df, x='Day', y='Lower Bound (q10)', \n",
    "                 color='crimson', linewidth=1.5, linestyle='--', label='Lower Bound (q10)')\n",
    "    sns.lineplot(data=df, x='Day', y='Upper Bound (q90)', \n",
    "                 color='forestgreen', linewidth=1.5, linestyle='--', label='Upper Bound (q90)')\n",
    "    \n",
    "    # Add markers to median forecast line for emphasis\n",
    "    plt.scatter(df['Day'], df['Median Forecast (q50)'], color='royalblue', s=40, zorder=5)\n",
    "    \n",
    "    # Calculate percent change for annotation\n",
    "    pct_change = ((q50[-1] - q50[0]) / q50[0] * 100)\n",
    "    change_direction = \"↑\" if pct_change > 0 else \"↓\"\n",
    "    change_color = \"green\" if pct_change > 0 else \"red\"\n",
    "    \n",
    "    # Add annotations\n",
    "    plt.annotate(f\"${q50[0]:,.2f}\", (0, q50[0]), xytext=(-10, -20), \n",
    "                textcoords='offset points', fontweight='bold')\n",
    "    plt.annotate(f\"${q50[-1]:,.2f} ({change_direction}{abs(pct_change):.1f}%)\", \n",
    "                (len(q50)-1, q50[-1]), xytext=(10, 10), \n",
    "                textcoords='offset points', fontweight='bold', color=change_color)\n",
    "    \n",
    "    # Set title and labels\n",
    "    plt.title(f\"{horizon}-Day Bitcoin Price Forecast\", fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.xlabel(\"Days Ahead\", fontsize=12)\n",
    "    plt.ylabel(\"Price ($)\", fontsize=12)\n",
    "    \n",
    "    # Add legend with custom position and style\n",
    "    plt.legend(loc='upper left', frameon=True, framealpha=0.9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "def train_model(model, train_loader, optimizer, num_epochs, device):\n",
    "    loss_history = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0\n",
    "        \n",
    "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        for xb, yb in loop:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            \n",
    "            preds = model(xb)\n",
    "            loss = quantile_loss(preds, yb, quantiles)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            loop.set_postfix(loss=loss.item())\n",
    "        \n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        loss_history.append(avg_loss)\n",
    "        \n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] Training Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Current learning rate: {current_lr}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(loss_history)\n",
    "    plt.title(\"Training Loss History\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nTraining completed! Final loss: {loss_history[-1]:.6f}\")\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    lookback = trial.suggest_int(\"lookback\", 30, 90, step=10)\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 64, 256, step=32)\n",
    "    num_stacked_layers = trial.suggest_int(\"num_layers\", 1, 5)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.0, 0.5, step=0.1)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64])\n",
    "    \n",
    "    print(f\"\\nTrial #{trial.number}:\")\n",
    "    print(f\"  lookback: {lookback}, hidden_size: {hidden_size}, num_layers: {num_stacked_layers}\")\n",
    "    print(f\"  dropout: {dropout}, learning_rate: {learning_rate}, batch_size: {batch_size}\")\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_lstm_data(\n",
    "        df, lookback=lookback, horizon=horizon, scaler_type=\"robust\"\n",
    "    )\n",
    "    \n",
    "    val_size = int(len(X_train) * 0.2)\n",
    "    X_val, y_val = X_train[-val_size:], y_train[-val_size:]\n",
    "    X_train, y_train = X_train[:-val_size], y_train[:-val_size]\n",
    "    \n",
    "    train_dataset = TSData(X_train, y_train)\n",
    "    val_dataset = TSData(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    model = QuantileLSTM(\n",
    "        input_size=1,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_stacked_layers,\n",
    "        dropout=dropout,\n",
    "        num_quantiles=len(quantiles)\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(15):\n",
    "        model.train()\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            loss = quantile_loss(preds, yb, quantiles)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                preds = model(xb)\n",
    "                val_loss += quantile_loss(preds, yb, quantiles).item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        print(f\"    Epoch {epoch+1}/15 - Validation Loss: {val_loss:.6f}\" + \n",
    "              (f\" (best)\" if val_loss < best_val_loss else \"\"))\n",
    "        \n",
    "        trial.report(val_loss, epoch)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= patience:\n",
    "            print(f\"    Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "            \n",
    "        if trial.should_prune():\n",
    "            print(f\"    Trial pruned at epoch {epoch+1}\")\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    print(f\"  Final validation loss: {best_val_loss:.6f}\")\n",
    "    return best_val_loss\n",
    "\n",
    "def run_hyperparameter_optimization(n_trials=50):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"STARTING HYPERPARAMETER OPTIMIZATION\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Number of trials: {n_trials}\")\n",
    "    print(\"Parameters being optimized:\")\n",
    "    print(\"  - lookback window (30-90 days)\")\n",
    "    print(\"  - hidden size (64-256 neurons)\")\n",
    "    print(\"  - number of LSTM layers (1-5)\")\n",
    "    print(\"  - dropout rate (0.0-0.5)\")\n",
    "    print(\"  - learning rate (1e-4 to 1e-2)\")\n",
    "    print(\"  - batch size (8, 16, 32, 64)\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"OPTIMIZATION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Best trial: #{study.best_trial.number}\")\n",
    "    print(f\"Best validation loss: {study.best_trial.value:.6f}\")\n",
    "    print(\"\\nBest hyperparameters:\")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        print(f\"  - {key}: {value}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    try:\n",
    "        fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "        fig1.show()\n",
    "        \n",
    "        fig2 = optuna.visualization.plot_param_importances(study)\n",
    "        fig2.show()\n",
    "        \n",
    "        fig3 = optuna.visualization.plot_contour(study)\n",
    "        fig3.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to display Optuna visualization: {str(e)}\")\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "def main():\n",
    "    best_params = run_hyperparameter_optimization(n_trials=20)\n",
    "    \n",
    "    lookback = best_params.get(\"lookback\", 60)\n",
    "    hidden_size = best_params.get(\"hidden_size\", 128)\n",
    "    num_stacked_layers = best_params.get(\"num_layers\", 3)\n",
    "    dropout = best_params.get(\"dropout\", 0.1)\n",
    "    learning_rate = best_params.get(\"learning_rate\", 0.001)\n",
    "    batch_size = best_params.get(\"batch_size\", 16)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"TRAINING FINAL MODEL WITH OPTIMAL HYPERPARAMETERS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Lookback window: {lookback} days (Default: 60)\")\n",
    "    print(f\"Hidden size: {hidden_size} neurons (Default: 128)\")\n",
    "    print(f\"LSTM layers: {num_stacked_layers} (Default: 3)\")\n",
    "    print(f\"Dropout rate: {dropout} (Default: 0.1)\")\n",
    "    print(f\"Learning rate: {learning_rate} (Default: 0.001)\")\n",
    "    print(f\"Batch size: {batch_size} (Default: 16)\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    X_train, y_train, X_test, y_test, scaler = prepare_lstm_data(\n",
    "        df, lookback=lookback, horizon=horizon, scaler_type=\"robust\"\n",
    "    )\n",
    "    \n",
    "    print(f\"Data shapes with lookback={lookback}:\")\n",
    "    print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}, y_test: {y_test.shape}\\n\")\n",
    "    \n",
    "    train_dataset = TSData(X_train, y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    print(f\"Using batch size: {batch_size} samples per batch\")\n",
    "    print(f\"Total batches per epoch: {len(train_loader)}\\n\")\n",
    "    \n",
    "    model = QuantileLSTM(\n",
    "        input_size=1, \n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_stacked_layers,\n",
    "        dropout=dropout,\n",
    "        num_quantiles=len(quantiles)\n",
    "    ).to(device)\n",
    "    \n",
    "    print(\"Model Architecture:\")\n",
    "    print(model)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params:,}\\n\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Using AdamW optimizer with learning rate: {learning_rate}\")\n",
    "    \n",
    "    print(\"\\nStarting training with optimal hyperparameters...\\n\")\n",
    "    model = train_model(model, train_loader, optimizer, num_epochs=num_epochs, device=device)\n",
    "    \n",
    "    print(\"\\nEvaluating model performance...\")\n",
    "    results = evaluate_quantile_predictions(model, X_train, y_train, X_test, y_test, scaler, lookback)\n",
    "    \n",
    "    print(\"\\nGenerating future forecasts...\")\n",
    "    X_last_window = X_test[-1].unsqueeze(0)\n",
    "    \n",
    "    print(f\"Using last window from test data: shape {X_last_window.shape}\")\n",
    "    \n",
    "    forecast = forecast_next_days(model, X_last_window, scaler, lookback, horizon, quantiles)\n",
    "    \n",
    "    last_actual = results[\"test_actual\"][-horizon:]\n",
    "    \n",
    "    plot_forecast(forecast, last_actual)\n",
    "    \n",
    "    print(\"\\nOptimization and modeling complete!\")\n",
    "    \n",
    "    return model, results, forecast\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984e5a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlitNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading streamlit-1.44.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.0.0 (from streamlit)\n",
      "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<6,>=4.0 (from streamlit)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.26.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\francisco avelar\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (23.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.1.4)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (10.2.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.31.0)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Downloading watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\francisco avelar\\appdata\\roaming\\python\\python312\\site-packages (from streamlit) (6.4)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Downloading narwhals-1.34.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\francisco avelar\\appdata\\roaming\\python\\python312\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\francisco avelar\\appdata\\roaming\\python\\python312\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2023.11.17)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\francisco avelar\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\francisco avelar\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Downloading streamlit-1.44.1-py3-none-any.whl (9.8 MB)\n",
      "   ---------------------------------------- 0.0/9.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 9.8/9.8 MB 61.2 MB/s eta 0:00:00\n",
      "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "   ---------------------------------------- 0.0/731.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 731.2/731.2 kB 29.3 MB/s eta 0:00:00\n",
      "Downloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 15.2/25.3 MB 73.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 64.1 MB/s eta 0:00:00\n",
      "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "   ---------------------------------------- 0.0/6.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.9/6.9 MB 70.6 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Downloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Downloading narwhals-1.34.1-py3-none-any.whl (325 kB)\n",
      "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: watchdog, toml, tenacity, smmap, pyarrow, narwhals, click, cachetools, blinker, pydeck, gitdb, gitpython, altair, streamlit\n",
      "Successfully installed altair-5.5.0 blinker-1.9.0 cachetools-5.5.2 click-8.1.8 gitdb-4.0.12 gitpython-3.1.44 narwhals-1.34.1 pyarrow-19.0.1 pydeck-0.9.1 smmap-5.0.2 streamlit-1.44.1 tenacity-9.1.2 toml-0.10.2 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script watchmedo.exe is installed in 'c:\\Users\\Francisco Avelar\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script streamlit.exe is installed in 'c:\\Users\\Francisco Avelar\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
